# Chat AI

This is a basic iOS SwiftUI MVVM Chat AI bot made using the [OpenAI HTTP API](https://platform.openai.com/docs/api-reference). The user enter a prompt and recieve either a predicted completion response (GPT-3) or a generated image (DALL-E).

## User Stories

The following functionality is completed:

- [x] User is greeted by a demo image/text indicating how to use each AI bot
- [x] User can switch tabs to access Chat AI (GPT-3), Image AI (DALL-E), and Settings
- [x] User can enter a prompt and Chat AI will predict a response
- [x] User can enter a prompt and Image AI will generate an image
- [x] User can copy messages to their clipboard
- [x] User can clear all chat messages
- [x] User receives haptic feedback for clearing/copying messages

## 3rd Party Libraries
* [OpenAI HTTP API](https://platform.openai.com/docs/api-reference)
* [OpenAISwift Wrapper Library](https://github.com/adamrushy/OpenAISwift)
* [AlertToast](https://github.com/elai950/AlertToast)
* [ActivityIndicatorView](https://github.com/exyte/ActivityIndicatorView)

## Analytics
* [Firebase](https://github.com/firebase/firebase-ios-sdk)

## Design
* [Canva](https://www.canva.com/)

## Video Walkthrough

Here's a walkthrough of implemented user stories:

<img src='demo.gif' title='Video Walkthrough' width='' alt='Video Walkthrough' /><br>
